import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE,ADASYN,RandomOverSampler
from imblearn.under_sampling import TomekLinks,RandomUnderSampler,OneSidedSelection
from imblearn.combine import SMOTEENN,SMOTETomek
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import cross_validate, KFold
from sklearn.ensemble import RandomForestClassifier as RFC
from sklearn.model_selection import cross_validate, KFold, GridSearchCV
from xgboost import XGBClassifier
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA

def normorlize(my_matrix):# 归一化数组
    scaler = MinMaxScaler()
    scaler.fit(my_matrix)
    scaler.data_max_
    my_matrix_normorlize = scaler.transform(my_matrix)
    return my_matrix_normorlize

base = ['A','G','C','T']
coden_dict = {}
m = 0
for i in range(4):
    for j in range(4):
        for k in range(4):
            coden_dict[base[i] + base[j] + base[k]] =m
            m+=1

def codenX(seq_list):  #特征编码
    # 字典创建
    coden_dict = {}
    m = 0
    for i in range(4):
        for j in range(4):
            for k in range(4):
                coden_dict[base[i] + base[j] + base[k]] = m
                m+=1
    vectors = np.zeros((64,1))           
    seq = seq_list  # 序列
    
    for i in range(len(seq)-2):
        vectors[coden_dict[seq[i:i+3]]]+=1    
    #vectors = normorlize(vectors)  # 归一化
    return vectors.tolist()
 
data = pd.read_csv("./model_build.csv")
feature = data.iloc[:,:10]
label = data.iloc[:,-1]
sequence = feature.Seq

table = pd.DataFrame(columns=list(coden_dict.keys()))

for Seq in sequence:
    data = np.squeeze(codenX(Seq))
    table.loc[len(table.index)]= data

data_all = pd.concat([table,data_1],axis=1)
data_all.drop("Seq",axis=1,inplace=True)

features = data_all.iloc[:,:-1]
labels = data_all.iloc[:,-1]

tl =SMOTEENN(random_state=1412)
X_tl,y_tl = tl.fit_resample(features,labels) 

param_grid_simple = {'num_boost_round': [*range(50,200,10)]
                     ,"eta":[*np.arange(0.01,0.5,0.01)]
                     ,"booster":["gbtree"]
                     ,"colsample_bytree":[*np.arange(0.3,1,0.1)]
                     ,"colsample_bynode":[*np.arange(0.5,1,0.1)]
                     ,"gamma":[*np.arange(0,1,0.05)]
                     ,"min_child_weight":[*range(1,50,5)]
                     ,"max_depth":[*range(1,50,5)]
                     ,"subsample":[*np.arange(0.2,1,0.2)]
                     ,"scale_pos_weight":[*np.arange(0.5,5,0.5)]
                    }
                   
xgb1 = XGBClassifier(random_state=1412)
cv = KFold(n_splits=5,shuffle=True,random_state=1412)
search = RandomizedSearchCV(estimator=xgb1
                            ,param_distributions=param_grid_simple
                            ,n_iter = 10000
                            ,scoring = "roc_auc"
                            ,verbose = True
                            ,cv = cv
                            ,random_state=1412
                            ,n_jobs=5
                           )
search = search.fit(X_tl,y_tl)                           
          
